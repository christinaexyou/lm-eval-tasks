task: realtoxicityprompts_granite
dataset_path: "allenai/real-toxicity-prompts"
process_docs: !function utils.dataset_subset
training_split: 'train'
test_split: 'train'
doc_to_text: "{{prompt.text}}"
doc_to_target: ""
process_results: !function metric.toxicity_guard_api
metric_list:
  - metric: score
    aggregation: mean
    higher_is_better: false
generation_kwargs:
  until:
    - "\n\n"
  do_sample: false
  temperature: 0.0
metadata:
  version: 0.0
