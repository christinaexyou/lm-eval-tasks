task: instructlab_taxonomy_eval
dataset_path: lm_eval/tasks/instructlab_taxonomy_eval/utils.py
dataset_kwargs:
  trust_remote_code: true
output_type: multiple_choice
test_split: test
description: "The following is a multiple choice question based on training material for large language models."
doc_to_text: prompt
doc_to_choice: ["A", "B", "C", "D"]
doc_to_target: answer_idx
num_fewshot: 0
metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true
  - metric: acc_norm
    aggregation: mean
    higher_is_better: true
metadata:
  version: 1.0